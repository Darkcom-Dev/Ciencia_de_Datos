{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SETTING UP YOUR DATA\n",
    "Once you have cleaned your dataset, the next job is to split the data into two\n",
    "segments for testing and training. It is very important not to test your model\n",
    "with the same data that you used for training. The ratio of the two splits\n",
    "should be approximately 70/30 or 80/20. This means that your training data\n",
    "should account for 70 percent to 80 percent of the rows in your dataset, and\n",
    "the other 20 percent to 30 percent of rows is your test data. It is vital to split\n",
    "your data by rows and not columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1: Training and test partitioning of the dataset 70/30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you split your data, it is important that you randomize all rows in the\n",
    "dataset. This helps to avoid bias in your model, as your original dataset might\n",
    "be arranged sequentially depending on the time it was collected or some other\n",
    "factor. Unless you randomize your data, you may accidentally omit important\n",
    "variance from the training data that will cause unwanted surprises when youapply the trained model to your test data. Fortunately, Scikit-learn provides a\n",
    "built-in function to shuffle and randomize your data with just one line of code\n",
    "(demonstrated in Chapter 13).\n",
    "After randomizing your data, you can begin to design your model and apply\n",
    "that to the training data. The remaining 30 percent or so of data is put to the\n",
    "side and reserved for testing the accuracy of the model.\n",
    "In the case of supervised learning, the model is developed by feeding the\n",
    "machine the training data and the expected output (y). The machine is able to\n",
    "analyze and discern relationships between the features (X) found in the\n",
    "training data to calculate the final output (y).\n",
    "The next step is to measure how well the model actually performs. A\n",
    "common approach to analyzing prediction accuracy is a measure called mean\n",
    "absolute error, which examines each prediction in the model and provides an\n",
    "average error score for each prediction.\n",
    "In Scikit-learn, mean absolute error is found using the model.predict function\n",
    "on X (features). This works by first plugging in the y values from the training\n",
    "dataset and generating a prediction for each row in the dataset. Scikit-learn\n",
    "will compare the predictions of the model to the correct outcome and measure\n",
    "its accuracy. You will know if your model is accurate when the error rate\n",
    "between the training and test dataset is low. This means that the model has\n",
    "learned the dataset’s underlying patterns and trends.\n",
    "Once the model can adequately predict the values of the test data, it is ready\n",
    "for use in the wild. If the model fails to accurately predict values from the test\n",
    "data, you will need to check whether the training and test data were properly\n",
    "randomized. Alternatively, you may need to change the model's\n",
    "hyperparameters.\n",
    "Each algorithm has hyperparameters; these are your algorithm settings. In\n",
    "simple terms, these settings control and impact how fast the model learns\n",
    "patterns and which patterns to identify and analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation\n",
    "Although the training/test data split can be effective in developing models\n",
    "from existing data, a question mark remains as to whether the model will\n",
    "work on new data. If your existing dataset is too small to construct an\n",
    "accurate model, or if the training/test partition of data is not appropriate, this\n",
    "can lead to poor estimations of performance in the wild.Fortunately, there is an effective workaround for this issue. Rather than\n",
    "splitting the data into two segments (one for training and one for testing), we\n",
    "can implement what is known as cross validation. Cross validation\n",
    "maximizes the availability of training data by splitting data into various\n",
    "combinations and testing each specific combination.\n",
    "Cross validation can be performed through two primary methods. The first\n",
    "method is exhaustive cross validation, which involves finding and testing all\n",
    "possible combinations to divide the original sample into a training set and a\n",
    "test set. The alternative and more common method is non-exhaustive cross\n",
    "validation, known as k-fold validation. The k-fold validation technique\n",
    "involves splitting data into k assigned buckets and reserving one of those\n",
    "buckets to test the training model at each round.\n",
    "To perform k-fold validation, data are first randomly assigned to k number of\n",
    "equal sized buckets. One bucket is then reserved as the test bucket and is used\n",
    "to measure and evaluate the performance of the remaining (k-1) buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2: k-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation process is repeated k number of times (“folds”). At each\n",
    "fold, one bucket is reserved to test the training model generated by the other\n",
    "buckets. The process is repeated until all buckets have been utilized as both atraining and test bucket. The results are then aggregated and combined to\n",
    "formulate a single model.\n",
    "By using all available data for both training and testing purposes, the k-fold\n",
    "validation technique dramatically minimizes potential error (such as\n",
    "overfitting) found by relying on a fixed split of training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Much Data Do I Need?\n",
    "A common question for students starting out in machine learning is how\n",
    "much data do I need to train my dataset? In general, machine learning works\n",
    "best when your training dataset includes a full range of feature combinations.\n",
    "What does a full range of feature combinations look like? Imagine you have a\n",
    "dataset about data scientists categorized by the following features:\n",
    "- University degree (X)\n",
    "- 5+ years professional experience (X)\n",
    "- Children (X)\n",
    "- Salary (y)\n",
    "To assess the relationship that the first three features (X) have to a data\n",
    "scientist’s salary (y), we need a dataset that includes the y value for each\n",
    "combination of features. For instance, we need to know the salary for data\n",
    "scientists with a university degree, 5+ years professional experience and that\n",
    "don’t have children, as well as data scientists with a university degree, 5+\n",
    "years professional experience and that do have children.\n",
    "The more available combinations, the more effective the model will be at\n",
    "capturing how each attribute affects y (the data scientist’s salary). This will\n",
    "ensure that when it comes to putting the model into practice on the test data\n",
    "or real-life data, it won’t immediately unravel at the sight of unseen\n",
    "combinations.\n",
    "At a minimum, a machine learning model should typically have ten times as\n",
    "many data points as the total number of features. So for a small dataset with\n",
    "three features, the training data should ideally have at least thirty rows.\n",
    "The other point to remember is that more relevant data is usually better than\n",
    "less. Having more relevant data allows you to cover more combinations and\n",
    "generally helps to ensure more accurate predictions. In some cases, it might\n",
    "not be possible or cost-effective to source data for every possible\n",
    "combination. In these cases, you will need to make do with the data that you\n",
    "have at your disposal.The following chapters will examine specific algorithms commonly used in\n",
    "machine learning. Please note that I include some equations out of necessity,\n",
    "and I have tried to keep them as simple as possible. Many of the machine\n",
    "learning techniques that we discuss in this book already have working\n",
    "implementations in your programming language of choice—no equation\n",
    "writing necessary."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
