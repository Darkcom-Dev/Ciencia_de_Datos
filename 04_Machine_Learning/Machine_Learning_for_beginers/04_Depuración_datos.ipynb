{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA SCRUBBING\n",
    "Much like many categories of fruit, datasets nearly always require some form\n",
    "of upfront cleaning and human manipulation before they are ready to digest.\n",
    "For machine learning and data science more broadly, there are a vast number\n",
    "of techniques to scrub data.\n",
    "Scrubbing is the technical process of refining your dataset to make it more\n",
    "workable. This can involve modifying and sometimes removing incomplete,\n",
    "incorrectly formatted, irrelevant or duplicated data. It can also entail\n",
    "converting text-based data to numerical values and the redesigning of\n",
    "features. For data practitioners, data scrubbing usually demands the greatest\n",
    "application of time and effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection\n",
    "To generate the best results from your data, it is important to first identify the\n",
    "variables most relevant to your hypothesis. In practice, this means being\n",
    "selective about the variables you select to design your model.\n",
    "Rather than creating a four-dimensional scatterplot with four features in the\n",
    "model, an opportunity may present to select two highly relevant features and\n",
    "build a two-dimensional plot that is easier to interpret. Moreover, preserving\n",
    "features that do not correlate strongly with the outcome value can, in fact,\n",
    "manipulate and derail the model’s accuracy. Consider the following table\n",
    "excerpt downloaded from kaggle.com documenting dying languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database: https://www.kaggle.com/the-guardian/extinct-languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say our goal is to identify variables that lead to a language becoming\n",
    "endangered. Based on this goal, it’s unlikely that a language’s “Name in\n",
    "Spanish” will lead to any relevant insight. We can therefore go ahead and\n",
    "delete this vector (column) from the dataset. This will help to prevent over-\n",
    "complication and potential inaccuracies, and will also improve the overall\n",
    "processing speed of the model.\n",
    "Secondly, the dataset holds duplicate information in the form of separate\n",
    "vectors for “Countries” and “Country Code.” Including both of these vectors\n",
    "doesn’t provide any additional insight; hence, we can choose to delete oneand retain the other.\n",
    "Another method to reduce the number of features is to roll multiple features\n",
    "into one. In the next table, we have a list of products sold on an e-commerce\n",
    "platform. The dataset comprises four buyers and eight products. This is not a\n",
    "large sample size of buyers and products—due in part to the spatial\n",
    "limitations of the book format. A real-life e-commerce platform would have\n",
    "many more columns to work with, but let’s go ahead with this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tabla protein shake nike sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to analyze the data in a more efficient way, we can reduce the\n",
    "number of columns by merging similar features into fewer columns. For\n",
    "instance, we can remove individual product names and replace the eight\n",
    "product items with a lower number of categories or subtypes. As all product\n",
    "items fall under the single category of “fitness,” we will sort by product\n",
    "subtype and compress the columns from eight to three. The three newly\n",
    "created product subtype columns are “Health Food,” “Apparel,” and\n",
    "“Digital.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla comida saluable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than recommending products to users according to other individual\n",
    "products, recommendations will instead be based on relationships between\n",
    "product subtypes.\n",
    "Nonetheless, this approach does uphold a high level of data relevancy.\n",
    "Buyers will be recommended health food when they buy other health food or\n",
    "when they buy apparel (depending on the level of correlation), and obviously\n",
    "not machine learning textbooks—unless it turns out that there is a strong\n",
    "correlation there! But alas, such a variable is outside the frame of this dataset.\n",
    "Remember that data reduction is also a business decision, and business\n",
    "owners in counsel with the data science team will need to consider the trade-\n",
    "off between convenience and the overall precision of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row Compression\n",
    "In addition to feature selection, there may also be an opportunity to reduce\n",
    "the number of rows and thereby compress the total number of data points.\n",
    "This can involve merging two or more rows into one. For example, in the\n",
    "following dataset, “Tiger” and “Lion” can be merged and renamed\n",
    "“Carnivore.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table comparativa compresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, by merging these two rows (Tiger & Lion), the feature values forboth rows must also be aggregated and recorded in a single row. In this case,\n",
    "it is viable to merge the two rows because they both possess the same\n",
    "categorical values for all features except y (Race Time)—which can be\n",
    "aggregated. The race time of the Tiger and the Lion can be added and divided\n",
    "by two.\n",
    "Numerical values, such as time, are normally simple to aggregate unless they\n",
    "are categorical. For instance, it would be impossible to aggregate an animal\n",
    "with four legs and an animal with two legs! We obviously can’t merge these\n",
    "two animals and set “three” as the aggregate number of legs.\n",
    "Row compression can also be difficult to implement when numerical values\n",
    "aren’t available. For example, the values “Japan” and “Argentina” are very\n",
    "difficult to merge. The countries “Japan” and “South Korea” can be merged,\n",
    "as they can be categorized as the same continent, “Asia” or “East Asia.”\n",
    "However, if we add “Pakistan” and “Indonesia” to the same group, we may\n",
    "begin to see skewed results, as there are significant cultural, religious,\n",
    "economic, and other dissimilarities between these four countries.\n",
    "In summary, non-numerical and categorical row values can be problematic to\n",
    "merge while preserving the true value of the original data. Also, row\n",
    "compression is normally less attainable than feature compression for most\n",
    "datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot Encoding\n",
    "After choosing variables and rows, you next want to look for text-based\n",
    "features that can be converted into numbers. Aside from set text-based values\n",
    "such as True/False (that automatically convert to “1” and “0” respectively),\n",
    "many algorithms and also scatterplots are not compatible with non-numerical\n",
    "data.\n",
    "One means to convert text-based features into numerical values is through\n",
    "one-hot encoding, which transforms features into binary form, represented as\n",
    "“1” or “0”—“True” or “False.” A “0,” representing False, means that the\n",
    "feature does not belong to a particular category, whereas a “1”—True or\n",
    "“hot”—denotes that the feature does belong to a set category.\n",
    "Below is another excerpt of the dataset on dying languages, which we can use\n",
    "to practice one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla Degree of Endangerment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, note that the values contained in the “No. of Speakers” column do not\n",
    "contain commas or spaces, e.g. 7,500,000 and 7 500 000. Although such\n",
    "formatting does make large numbers clearer for our eyes, programming\n",
    "languages don’t require such niceties. In fact, formatting numbers can lead to\n",
    "an invalid syntax or trigger an unwanted result, depending on the\n",
    "programming language you use. So remember to keep numbers unformatted\n",
    "for programming purposes. Feel free, though, to add spacing or commas at\n",
    "the data visualization stage, as this will make it easier for your audience to\n",
    "interpret!\n",
    "On the right-hand-side of the table is a vector categorizing the degree of\n",
    "endangerment of the nine different languages. This column we can convert to\n",
    "numerical values by applying the one-hot encoding method, as demonstrated\n",
    "in the subsequent table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using one-hot encoding, the dataset has expanded to five columns and we\n",
    "have created three new features from the original feature (Degree of\n",
    "Endangerment). We have also set each column value to “1” or “0,”\n",
    "depending on the original category value.\n",
    "This now makes it possible for us to input the data into our model and choose\n",
    "from a wider array of machine learning algorithms. The downside is that we\n",
    "have more dataset features, which may lead to slightly longer processing\n",
    "time. This is nonetheless manageable, but it can be problematic for datasets\n",
    "where original features are split into a larger number of new features.\n",
    "One hack to minimize the number of features is to restrict binary cases to a\n",
    "single column. As an example, there is a speed dating dataset on kaggle.com\n",
    "that lists “Gender” in a single column using one-hot encoding. Rather than\n",
    "create discrete columns for both “Male” and “Female,” they merged these\n",
    "two features into one. According to the dataset’s key, females are denoted as\n",
    "“0” and males are denoted as “1.” The creator of the dataset also used this\n",
    "technique for “Same Race” and “Match.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database: https://www.kaggle.com/annavictoria/speed-dating-experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning\n",
    "Binning is another method of feature engineering that is used to convert\n",
    "numerical values into a category.\n",
    "Whoa, hold on! Didn’t you say that numerical values were a good thing? Yes,\n",
    "numerical values tend to be preferred in most cases. Where numerical values\n",
    "are less ideal, is in situations where they list variations irrelevant to the goals\n",
    "of your analysis. Let’s take house price evaluation as an example. The exact\n",
    "measurements of a tennis court might not matter greatly when evaluating\n",
    "house prices. The relevant information is whether the house has a tennis\n",
    "court. The same logic probably also applies to the garage and the swimming\n",
    "pool, where the existence or non-existence of the variable is more influential\n",
    "than their specific measurements.\n",
    "The solution here is to replace the numeric measurements of the tennis court\n",
    "with a True/False feature or a categorical value such as “small,” “medium,”\n",
    "and “large.” Another alternative would be to apply one-hot encoding with “0”\n",
    "for homes that do not have a tennis court and “1” for homes that do have atennis court."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Data\n",
    "Dealing with missing data is never a desired situation. Imagine unpacking a\n",
    "jigsaw puzzle that you discover has five percent of its pieces missing.\n",
    "Missing values in a dataset can be equally frustrating and will ultimately\n",
    "interfere with your analysis and final predictions. There are, however,\n",
    "strategies to minimize the negative impact of missing data.\n",
    "One approach is to approximate missing values using the mode value. The\n",
    "mode represents the single most common variable value available in the\n",
    "dataset. This works best with categorical and binary variable types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1: A visual example of the mode and median respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach to manage missing data is to approximate missing\n",
    "values using the median value, which adopts the value(s) located in the\n",
    "middle of the dataset. This works best with integers (whole numbers) and\n",
    "continuous variables (numbers with decimals).\n",
    "As a last resort, rows with missing values can be removed altogether. The\n",
    "obvious downside to this approach is having less data to analyze and\n",
    "potentially less comprehensive results."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
