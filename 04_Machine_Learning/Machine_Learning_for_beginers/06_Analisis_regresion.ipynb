{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSION ANALYSIS\n",
    "As the “Hello World” of machine learning algorithms, regression analysis is\n",
    "a simple supervised learning technique used to find the best trendline to\n",
    "describe a dataset.\n",
    "The first regression analysis technique that we will examine is linear\n",
    "regression, which uses a straight line to describe a dataset. To unpack this\n",
    "simple technique, let’s return to the earlier dataset charting Bitcoin values to\n",
    "the US Dollar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tabla bitcoin price vs dias transpirados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you’re back in high school and it's the year 2015 (which is probably\n",
    "much more recent than your actual year of graduation!). During your senior\n",
    "year, a news headline piques your interest in Bitcoin. With your natural\n",
    "tendency to chase the next shiny object, you tell your family about your\n",
    "cryptocurrency aspirations. But before you have a chance to bid for your first\n",
    "Bitcoin on Coinbase, your father intervenes and insists that you try paper\n",
    "trading before you go risking your life savings. “Paper trading” is using\n",
    "simulated means to buy and sell an investment without involving actual\n",
    "money.\n",
    "So over the next twenty-four months, you track the value of Bitcoin and write\n",
    "down its value at regular intervals. You also keep a tally of how many days\n",
    "have passed since you first started paper trading. You never anticipated to\n",
    "still be paper trading after two years, but unfortunately, you never got achance to enter the cryptocurrency market. As suggested by your father, you\n",
    "waited for the value of Bitcoin to drop to a level you could afford. But\n",
    "instead, the value of Bitcoin exploded in the opposite direction.\n",
    "Nonetheless, you haven’t lost hope of one day owning Bitcoin. To assist your\n",
    "decision on whether you continue to wait for the value to drop or to find an\n",
    "alternative investment class, you turn your attention to statistical analysis.\n",
    "You first reach into your toolbox for a scatterplot. With the blank scatterplot\n",
    "in your hands, you proceed to plug in your x and y coordinates from your\n",
    "dataset and plot Bitcoin values from 2015 to 2017. However, rather than use\n",
    "all three columns from the table, you select the second (Bitcoin price) and\n",
    "third (No. of Days Transpired) columns to build your model and populate the\n",
    "scatterplot (shown in Figure 1). As we know, numerical values (found in the\n",
    "second and third columns) are easy to plug into a scatterplot and require no\n",
    "special conversion or one-hot encoding. What’s more, the first and third\n",
    "columns contain the same variable of “time” and the third column alone is\n",
    "sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1: Bitcoin values from 2015-2017 plotted on a scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your goal is to estimate what Bitcoin will be valued at in the future, the y-\n",
    "axis plots the dependent variable, which is “Bitcoin Price.” The independent\n",
    "variable (X), in this case, is time. The “No. of Days Transpired” is thereby\n",
    "plotted on the x-axis.After plotting the x and y values on the scatterplot, you can immediately see a\n",
    "trend in the form of a curve ascending from left to right with a steep increase\n",
    "between day 607 and day 736. Based on the upward trajectory of the curve, it\n",
    "might be time to quit hoping for a drop in value.\n",
    "However, an idea suddenly pops up into your head. What if instead of\n",
    "waiting for the value of Bitcoin to fall to a level that you can afford, you\n",
    "instead borrow from a friend and purchase Bitcoin now at day 736? Then,\n",
    "when the value of Bitcoin rises further, you can pay back your friend and\n",
    "continue to earn asset appreciation on the Bitcoin you fully own.\n",
    "In order to assess whether it’s worth borrowing from your friend, you will\n",
    "need to first estimate how much you can earn in potential profit. Then you\n",
    "need to figure out whether the return on investment will be adequate to pay\n",
    "back your friend in the short-term.\n",
    "It’s now time to reach into the third compartment of the toolbox for an\n",
    "algorithm. One of the simplest algorithms in machine learning is regression\n",
    "analysis, which is used to determine the strength of a relationship between\n",
    "variables. Regression analysis comes in many forms, including linear, non-\n",
    "linear, logistic, and multilinear, but let’s take a look first at linear regression.\n",
    "Linear regression comprises a straight line that splits your data points on a\n",
    "scatterplot. The goal of linear regression is to split your data in a way that\n",
    "minimizes the distance between the regression line and all data points on the\n",
    "scatterplot. This means that if you were to draw a vertical line from the\n",
    "regression line to each data point on the graph, the aggregate distance of each\n",
    "point would equate to the smallest possible distance to the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2: Linear regression line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression line is plotted on the scatterplot in Figure 2. The technical\n",
    "term for the regression line is the hyperplane, and you will see this term used\n",
    "throughout your study of machine learning. A hyperplane is practically a\n",
    "trendline—and this is precisely how Google Sheets titles linear regression in\n",
    "its scatterplot customization menu.\n",
    "Another important feature of regression is slope, which can be conveniently\n",
    "calculated by referencing the hyperplane. As one variable increases, the other\n",
    "variable will increase at the average value denoted by the hyperplane. The\n",
    "slope is therefore very useful in formulating predictions. For example, if you\n",
    "wish to estimate the value of Bitcoin at 800 days, you can enter 800 as your x\n",
    "coordinate and reference the slope by finding the corresponding y value\n",
    "represented on the hyperplane. In this case, the y value is USD $1,850."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3: The value of Bitcoin at day 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in Figure 3, the hyperplane reveals that you actually stand to lose\n",
    "money on your investment at day 800 (after buying on day 736)! Based on\n",
    "the slope of the hyperplane, Bitcoin is expected to depreciate in value\n",
    "between day 736 and day 800—despite no precedent in your dataset for\n",
    "Bitcoin ever dropping in value.\n",
    "While it’s needless to say that linear regression isn’t a fail-proof method to\n",
    "picking investment trends, the trendline does offer a basic reference point to\n",
    "predict the future. If we were to use the trendline as a reference point earlier\n",
    "in time, say at day 240, then the prediction posted would have been more\n",
    "accurate. At day 240 there is a low degree of deviation from the hyperplane,\n",
    "while at day 736 there is a high degree of deviation. Deviation refers to the\n",
    "distance between the hyperplane and the data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4: The distance of the data points to the hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the closer the data points are to the regression line, the more\n",
    "accurate the final prediction. If there is a high degree of deviation between\n",
    "the data points and the regression line, the slope will provide less accurate\n",
    "predictions. Basing your predictions on the data point at day 736, where there\n",
    "is high deviation, results in poor accuracy. In fact, the data point at day 736\n",
    "constitutes an outlier because it does not follow the same general trend as the\n",
    "previous four data points. What’s more, as an outlier it exaggerates the\n",
    "trajectory of the hyperplane based on its high y-axis value. Unless future data\n",
    "points scale in proportion to the y-axis values of the outlier data point, the\n",
    "model’s predictive accuracy will suffer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation Example\n",
    "Although your programming language will take care of this automatically,\n",
    "it’s useful to understand how linear regression is actually calculated. We will\n",
    "use the following dataset and formula to perform linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The final two columns of the table are not part of the original dataset and have been added for convenience to complete the following equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecuasiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:\n",
    "Σ = Total sum\n",
    "Σx = Total sum of all x values (1 + 2 + 1 + 4 + 3 = 11)\n",
    "Σy = Total sum of all y values (3 + 4 + 2 + 7 + 5 = 21)\n",
    "Σxy = Total sum of x*y for each row (3 + 8 + 2 + 28 + 15 = 56)\n",
    "Σx = Total sum of x*x for each row (1 + 4 + 1 + 16 + 9 = 31)\n",
    "n = Total number of rows. In the case of this example, n = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas ecuaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A =\n",
    "((21 x 31) – (11 x 56)) / (5(31) – 11 )\n",
    "(651 – 616) / (155 – 121)\n",
    "35 / 34\n",
    "1.029\n",
    "2\n",
    "B =\n",
    "(5(56) – (11 x 21)) / (5(31) – 11 )\n",
    "(280 – 231) / (155 – 121)\n",
    "49 / 34\n",
    "1.44\n",
    "Insert the “a” and “b” values into a linear equation.\n",
    "y = a + bx\n",
    "y = 1.029 + 1.441x\n",
    "The linear equation y = 1.029 + 1.441x dictates how to draw the hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 5: The linear regression hyperplane plotted on the scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now test the regression line by looking up the coordinates for x = 2.\n",
    "y = 1.029 + 1.441(x)\n",
    "y = 1.029 + 1.441(2)\n",
    "y = 3.911\n",
    "In this case, the prediction is very close to the actual result of 4.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "A large part of data analysis boils down to a simple question: is something\n",
    "“A” or “B?” Is it “positive” or “negative?” Is this person a “potential\n",
    "customer” or “not a potential customer?” Machine learning accommodates\n",
    "such questions through logistic equations, and specifically through what is\n",
    "known as the sigmoid function. The sigmoid function produces an S-shaped\n",
    "curve that can convert any number and map it into a numerical value between\n",
    "0 and 1, but it does so without ever reaching those exact limits.\n",
    "A common application of the sigmoid function is found in logistic regression.\n",
    "Logistic regression adopts the sigmoid function to analyze data and predict\n",
    "discrete classes that exist in a dataset. Although logistic regression shares a\n",
    "visual resemblance to linear regression, it is technically a classification\n",
    "technique. Whereas linear regression addresses numerical equations and\n",
    "forms numerical predictions to discern relationships between variables,logistic regression predicts discrete classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 6: An example of logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is typically used for binary classification to predict two\n",
    "discrete classes, e.g. pregnant or not pregnant. To do this, the sigmoid\n",
    "function (shown as follows) is added to compute the result and convert\n",
    "numerical results into an expression of probability between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y=\\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic sigmoid function above is calculated as “1” divided by “1” plus\n",
    "“e” raised to the power of negative “x,” where:\n",
    "x = the numerical value you wish to transform\n",
    "e = Euler's constant, 2.718\n",
    "In a binary case, a value of 0 represents no chance of occurring, and 1\n",
    "represents a certain chance of occurring. The degree of probability for values\n",
    "located between 0 and 1 can be calculated according to how close they rest to\n",
    "0 (impossible) or 1 (certain possibility) on the scatterplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 7: A sigmoid function used to classify data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the found probabilities we can assign each data point to one of two\n",
    "discrete classes. As seen in Figure 7, we can create a cut-off point at 0.5 to\n",
    "classify the data points into classes. Data points that record a value above 0.5\n",
    "are classified as Class A, and any data points below 0.5 are classified as Class\n",
    "B. Data points that record a result of exactly 0.5 are unclassifiable, but such\n",
    "instances are rare due to the mathematical component of the sigmoid\n",
    "function.\n",
    "Please also note that this formula alone does not produce the hyperplane\n",
    "dividing discrete categories as seen earlier in Figure 6. The statistical formula\n",
    "for plotting the logistic hyperplane is somewhat more complicated and can be\n",
    "conveniently plotted using your programming language.\n",
    "Given its strength in binary classification, logistic regression is used in many\n",
    "fields including fraud detection, disease diagnosis, emergency detection, loan\n",
    "default detection, or to identify spam email through the process of identifying\n",
    "specific classes, e.g. non-spam and spam. However, logistic regression can\n",
    "also be applied to ordinal cases where there are a set number of discrete\n",
    "values, e.g. single, married, and divorced.\n",
    "Logistic regression with more than two outcome values is known asmultinomial logistic regression, which can be seen in Figure 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 8: An example of multinomial logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two tips to remember when performing logistic regression are that the data\n",
    "should be free of missing values and that all variables are independent of\n",
    "each other. There should also be sufficient data for each outcome value to\n",
    "ensure high accuracy. A good starting point would be approximately 30-50\n",
    "data points for each outcome, i.e. 60-100 total data points for binary logistic\n",
    "regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine\n",
    "As an advanced category of regression, support vector machine (SVM)\n",
    "resembles logistic regression but with stricter conditions. To that end, SVM is\n",
    "superior at drawing classification boundary lines. Let’s examine what this\n",
    "looks like in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 9: Logistic regression versus SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot in Figure 9 consists of data points that are linearly separable\n",
    "and the logistic hyperplane (A) splits the data points into two classes in a way\n",
    "that minimizes the distance between all data points and the hyperplane. The\n",
    "second line, the SVM hyperplane (B), likewise separates the two clusters, but\n",
    "from a position of maximum distance between itself and the two clusters.\n",
    "You will also notice a gray area that denotes margin, which is the distance\n",
    "between the hyperplane and the nearest data point, multiplied by two. The\n",
    "margin is a key feature of SVM and is important because it offers additional\n",
    "support to cope with new data points that may infringe on a logistic\n",
    "regression hyperplane. To illustrate this scenario, let’s consider the same\n",
    "scatterplot with the inclusion of a new data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 10: A new data point is added to the scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data point is a circle, but it is located incorrectly on the left side of\n",
    "the logistic regression hyperplane (designated for stars). The new data point,\n",
    "though, remains correctly located on the right side of the SVM hyperplane\n",
    "(designated for circles) courtesy of ample “support” supplied by the margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 11: Mitigating anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful application case of SVM is for mitigating anomalies. A\n",
    "limitation of standard logistic regression is that it goes out of its way to fit\n",
    "anomalies (as seen in the scatterplot with the star in the bottom right corner in\n",
    "Figure 11). SVM, however, is less sensitive to such data points and actually\n",
    "minimizes their impact on the final location of the boundary line. In Figure\n",
    "11, we can see that Line B (SVM hyperplane) is less sensitive to the\n",
    "anomalous star on the right-hand side. SVM can thus be used as one method\n",
    "to fight anomalies.\n",
    "The examples seen so far have comprised two features plotted on a two-\n",
    "dimensional scatterplot. However, SVM’s real strength is found in high-\n",
    "dimensional data and handling multiple features. SVM has numerous\n",
    "variations available to classify high-dimensional data, known as “kernels,”\n",
    "including linear SVC (seen in Figure 12), polynomial SVC, and the Kernel\n",
    "Trick. The Kernel Trick is an advanced solution to map data from a low-\n",
    "dimensional to a high-dimensional space. Transitioning from a two-\n",
    "dimensional to a three-dimensional space allows you to use a linear plane to\n",
    "split the data within a 3-D space, as seen in Figure 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 12: Example of linear SVC"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
